####### ----------------------------------------------------------#######
###           Data preparation and analysis code                   ###
####### ----------------------------------------------------------#######


# The purpose of this code is to allow the user to explore the evolving data sets.
#  There are two analysis branches, one for growth and the other for mortality .
#
#  Users set many output conditions in Global.R
#
#   In step 1 the conditions for the analysis are loaded.  Step 2 involves either
#   reconstructing the data from FIA SQL tables or loading existing data sets
#   and avoiding that time commitment.  Climate data and lat/longitude data are
#   loaded as well. Step 3 prepares the data for analysis and determines data 
#   conditions.  Step 4 is the analysis of data and generation of result tables.
#   Results are generated by species across the 3-state range, by state, and by
#   climate variable values (the initial-visit climate variable value and the 
#    change in climate variable value between visits).  Step 5 is the generation   
#    of figures. 
#
#     The code saves estimation output so that a Shiny dashboard can read and
#    display findings graphically and in ways that will not be done for the 
#    manuscript.
#




#### 1) Loading constants, libraries, and functions----------------------------

source("Global.R")
source(paste0(CODE.LOC, "Functions.R"))

library(furrr)
library(parallel)
library(RSQLite) # For obtaining SQLite FIA databases
library(tictoc)  # For development, timing routines.
library(data.table)
library(matrixStats) # For fast iteration processing
library(abind) # for combining matrices into arrays
library(ggrepel) # For plotting, avoiding overlapping labels

#### 2) Base data prep --------------------------------------------------------
# These are the base data sets that will be transformed by the analysis types.



### ==> Load the tree/plot data ===================================================

# Working backwards: is the tree/plot data set ready to go? If so, let's unzip the CSV file and move ahead. 
#   If not, do the SQLite databases for CA/OR/WA need data extracted?  Those datasets are then processed by the 
# code to produce the tree/plot dataset.  
if(all(file.exists(file.path(DATA.LOC, "Distilled_Tree_Data.zip")), file.exists(file.path(DATA.LOC, "N_Plots.csv")))) {
  tree.plt.data <- read_csv(unzip(paste0(DATA.LOC, "Distilled_Tree_Data.zip"), "Distilled_Tree_Data.csv")) # This unzips the folder in the parent directory.
  plotN2 <- read_csv(file.path(DATA.LOC, "N_Plots.csv"), show_col_types = FALSE)
  file.remove("Distilled_Tree_Data.csv")
} else {
  ## Some info (harvest, fire deaths for trees) was absent in the range-shift analysis.  We need to introduce it here. 
  ##  The following code relies on downloaded and zipped SQLite FIA data from Oregon, Washington, and CA.  See the Global.R file:
  #    the zip files should be placed in the same folder, defined by SQL.LOC.  The following code unpacks, reduces, combines, and saves
  #   the PLOT, TREE, and COND files for each state as a zipped RDS file.  
  if (file.exists(paste0(DATA.LOC, "Addl_PlotTreeInfo.zip")) == FALSE) {
    source(paste0(CODE.LOC, "FIA_SQL_compile.R"))  # Data filtering for TREE occurs here as well. 
  }
  
  fia.tables <- read_rds(unzip(paste0(DATA.LOC, "Addl_PlotTreeInfo.zip"), "Addl_PlotTreeInfo.rds")) # This unzips the folder in the parent directory.
  
  # Deleting written RDS file (~200+ MB)
  if (file.exists("Addl_PlotTreeInfo.rds") == TRUE) {
    file.remove("Addl_PlotTreeInfo.rds")
  }
  
  # Now hopping over to run this code which will save the tree/plot zipped CSV file.
  source(paste0(CODE.LOC, "FIA_data_distillation.R"))
  
}

### ==> Load the climate data ===================================================
if (file.exists(paste0(DATA.LOC, "Climate_plot_results.rds")) == FALSE) {
  source(paste0(CODE.LOC, "Climate_Dat_Preparation.R"))  # Data filtering for TREE occurs here as well. 
}

climate.data <- read_rds(paste0(DATA.LOC, "Climate_plot_results.rds")) 

### ==> Load the latitude/longitude data ===================================================
# Bringing in Lat/Lon from earlier study. Needed to recreate State_Plot (above) for the join.  
latlon <- read_csv(paste0(DATA.LOC, "PlotLatLon.csv")) %>% select(-n)

# Selecting annual or summer climate variable, adding the variable State_Plot from the Groom/Vicente analysis 
# to enable joining of lat/lon info.
climate.use <- climate.data[[grep(CLIM.SUMMARY, names(climate.data))]] %>% 
  select (puid, pre_mean, difference) %>%
  rowwise() %>%
  mutate(plot = strsplit(puid, "_")[[1]][1], 
         state = strsplit(puid, "_")[[1]][2],
         State_Plot = as.numeric(paste0(plot, state))) %>%
  left_join(latlon, by = "State_Plot") %>%
  dplyr::select(-plot, -state, -State_Plot)

data.use <- left_join(tree.plt.data %>% dplyr::select(-LAT, -LON), climate.use, by = "puid")
dat.na <- data.use %>% filter(is.na(difference)) # 7 plots for which we don't have AET data
data.use <- anti_join(data.use, dat.na)


treedat.use <- data.use 

n_domain <- length(DOMAIN.LEVELS)

PlotDat <- treedat.use %>% dplyr::select(STATECD, puid, ESTN_UNIT, STRATUMCD, w) %>% 
  distinct() %>%
  mutate(stratum = as.numeric(paste0(STRATUMCD, 0, ESTN_UNIT, 0, STATECD))) 
#pd.check <- PlotDat %>% select(State_Plot) %>% distinct() # Yes, same number of rows


# Investigating weights.  Do we use area weights (Wh) or plot weights (n_h/N)?
# We do need to correct the number of plots per stratum so that the stratum-level mean 
# can be calculated.

plotN3 <- plotN2 %>% group_by(stratum) %>%
  summarize(n_h.plts = n())
  # Adding "n_h.plts" to data:
PlotDat <- left_join(PlotDat, plotN3, by = c("stratum"))

# tot.n <- sum(plotN3$n_h.plts)  # This is the total number of all plots in all strata. 
#  Not used in the analysis (at this point).

# Now just checking to see how Wh and n_h/N compare.
#  plt.use <- PlotDat %>% group_by(stratum, w) %>%
#  summarize(n.plts = n()) %>%
#  left_join(plotN3, by = "Stratum") %>%
#  mutate(w.plts = n_h.plts / tot.n) 

#  It looks like the fit between Wh and n_h/N is pretty tightly linear.  
#   The fit is not quite 1:1.  It becomes noisy 
#ggplot(plt.use, aes(w.plts, w)) + geom_point() +     
#  geom_smooth(col = "orange", se = FALSE) +
#  geom_smooth(method = "lm", col = "blue") +
#    geom_abline(slope = 1, intercept = 0) + 
# xlim(0, 0.0025) + ylim(0, 0.0025)
  

#### 3) Specialized data prep --------------------------------------------------------
## First the data are summarized by species and climate variable (clim.mort.resp.fcn, 
#   clim.growth.resp.fcn).  Then the data are combined into arrays for 
#    analysis (parse.tree.clim.fcn).
tree.mort.dat <- purrr::map(sel.spp, clim.mort.resp.fcn, clim.var = CLIM.VAR.USE, treedat.sel = treedat.use, clim.dat = climate.use) 

# Create lists of tree growth and number of trees that grew in each plot
tree.grow.dat <- purrr::map(sel.spp, clim.growth.resp.fcn, clim.var = CLIM.VAR.USE, treedat.sel = treedat.use, clim.dat = climate.use) 


# Combining data into arrays and such, preparing for analysis.
arrays.mort <- parse.tree.clim.fcn(tree.mort.dat, clim.var = CLIM.VAR.USE, analysis.type = "mort", resp.dat = "died.out", tot.dat = "all.trees", selected.spp = SEL.SPP, clim.dat = climate.use)

arrays.grow <- parse.tree.clim.fcn(tree.grow.dat, clim.var = CLIM.VAR.USE, analysis.type = "grow", resp.dat = "growth.val", tot.dat = "growth.n.trees", selected.spp = SEL.SPP, clim.dat = climate.use)

if(file.exists(paste0(DATA.LOC, "analysis.arrays.zip")) == FALSE){
  write_rds(list(arrays.mort = arrays.mort, arrays.grow = arrays.grow, PlotDat = PlotDat), file = paste0(DATA.LOC, "analysis.arrays.RDS"))
  zip(zipfile = file.path(DATA.LOC, "analysis.arrays.zip"), files = file.path(DATA.LOC, "analysis.arrays.RDS"),
      flags = '-r9Xj' )  # This weird bit keeps the parent directory from being included in the zip folder
  
  # Deleting written CSV file (~200 MB), cleaning up after the data zip process. 
  if (file.exists(file.path(DATA.LOC, "analysis.arrays.RDS")) == TRUE) {
    file.remove(file.path(DATA.LOC, "analysis.arrays.RDS"))
  }
  
}


#### 4) Analysis and plotting  --------------------------------------------------------


## Fire mortality: what proportion died from fire (and other causes)?  This info is only generated for pathway 1 and mortality.
if (CALC.FIREPROP == TRUE) {
  fire.frac.table.fcn(tablename = "Fire_Prop_mort.csv", tableloc = paste0(RESULTS1.LOC, "Mort_figs_", CLIM.VAR.USE, "/"), treedat = treedat.use, parseddat = arrays.mort)  
}

# Determining cause of death frequency for trees by species:
death.prop <- read_csv(paste0(RESULTS1.LOC, "Mort_figs_", CLIM.VAR.USE, "/Fire_Prop_mort.csv"), show_col_types = FALSE) %>%
  group_by(spp) %>%
  reframe(
    n = sum(tot),
    n.dead = sum(tot.dead),
    frac.fire = sum(tot.burn)/n.dead,
    frac.insect.disease = sum(tot.insect)/n.dead + sum(tot.disease)/n.dead,
    frac.animal = sum(tot.animal)/n.dead,
    frac.vegetation = sum(tot.vegetation)/n.dead,
    frac.unknown = sum(tot.unknown)/n.dead,
    frac.silviculture = sum(tot.silviculture)/n.dead,
  ) %>%
  mutate(frac.dead = n.dead/n)

#write_csv(death.prop, "death.prop.csv")


# If desired, the analysis will obtain mortality estimates for the selected species
#  by state and overall. These values can be used to evaluate species for inclusion in the
#  main analysis.  200 iterations, 16 cores = 4 minutes
tic()
if(RUN.STATES == TRUE) {
  source(paste0(CODE.LOC, "Overall_Mort_Est.R"))
}
toc()




# The remaining code breaks up the analyses by type (mortality, growth) and climate variable (AET).

tic() 
# For ANALYSIS.PATHWAY == 1, one climate variable, and 16 dedicated cores, the analysis takes about 8 minutes.

for(k in 1:length(ANALYSIS.TYPE)) {  # 1 = grow, 2 = mortality
  

    # Need climate names for files and axes.
    clim.names <- read_csv(paste0(DATA.LOC, "ClimateNames.csv"), show_col_types = FALSE) %>%
      filter(filename == CLIM.VAR.USE)

    var1 <- clim.names$values[grep("pre", clim.names$values)]
    var.delt <- clim.names$values[grep("d", clim.names$values)]
    

    var.label <- clim.names$label[clim.names$values == var1]
    #var.filename <- clim.names$filename[clim.names$values == var1]
    var.delt.label <- clim.names$label[clim.names$values == var.delt]
    
    # Obtaining the data to work with: Grabbing the list objects from above
    mort.grow.dat <- get(paste0("arrays.", ANALYSIS.TYPE[k])) 
    
    vals_dat <- mort.grow.dat$vals_dat
    all_dat <- mort.grow.dat$all_dat
    domain.array <- mort.grow.dat$domain.array
    state.array <- mort.grow.dat$state.array
    state.n <- mort.grow.dat$state.n
    domain.matrix <- mort.grow.dat$domain.matrix
    centroid.array <- mort.grow.dat$centroid.array
    domain.n <- mort.grow.dat$domain.n 
    quant.lims <- mort.grow.dat$quant.lims
    quant.lims.delta <- mort.grow.dat$quant.lims.delt
    

    ## First, adjusting the species list
    #spp.id <- paste0("X", spp.list)     # Can use SEL.SPP
    spp.list <- as.numeric(gsub("X", "", SEL.SPP))
    
    strat.num <- length(unique(vals_dat$stratum))

    n.spp <- length(SEL.SPP)
    
    
    # Strata for bootstrap resampling procedure
    strata <- unique(vals_dat$stratum)
    strata.num <- vals_dat %>% dplyr::select(stratum, puid) %>%
      ungroup() %>% 
      mutate(row.id = row_number())
    
    
    plan(multisession, workers = n.cores) # Setting up parallel computing. See Global.R for n.cores.
    
    
    ## Quantile estimates for mortality or growth, across select species.
    domain.index <- 1:n_domain
    

    ## Generating the bootstrap values: 
   # 200 iterations = 104.99 s, or 1.75 min, or 29.2 hours
   # 1000 iterations, 10 cores, batches of 100: 50 s
  # 1000 iterations, 5 cores, batches of 200:  41 s # This appears best
  # 1000 iterations, 4 cores, batches of 250: 44 s
  # 1000 iterations, 1 core, batch of 1000: 110 s  
    #tic()
    bootstrap_results <- generate_bootstrap_array.fcn(
      vals.dat = vals_dat,
      all.dat = all_dat,
      domain.array = domain.array,
      domain.n = domain.n,
      selected.spp = SEL.SPP,
      n_iter = BS.N, 
      strata.num = strata.num,
      PlotDat = PlotDat
    )
  #toc()
    # Finding and saving domain summaries
    domain.summaries <- domain.index %>% 
      purrr::map(\(d) domain.sum.fcn(bootstrap_results, d, domain_n = domain.n)) %>%
      do.call(rbind, .) %>%
      arrange(Species, Domain)
    
    saveRDS(list(bootstrap_results = bootstrap_results, domain.summaries = domain.summaries, all_dat = all_dat), 
            file = paste0(save.loc.fcn(k), "Domain_Analysis_Output.RDS"))
    
 
    ## TO ADAPT THE INPUT WITHOUT RERUNNING THE BOOTSTRAP/PERMUTATION TEST SKIP THE    
    #   BOOTSTRAP AND saveRDS() CALL AND RUN THE FOLLOWING. THIS WAS USED TO RENAME THE
    #   CHANGE DOMAINS FROM ABOVE/BELOW TO INCREASING/STABLE.
#    dmd <- readRDS(paste0(save.loc.fcn(k), "Domain_Analysis_Output.RDS"))
#    bootstrap_results = dmd$bootstrap_results
#    domain.summaries = dmd$domain.summaries
#   all_dat = dmd$all_dat
    
    
    ## The code in this section is dedicated to preparing data files for plotting the differences in six-domain results.
    ## This process has two steps: first, the domain matrix pairs are subtracted from one another 
    #  using the domain.diff.fcn function.  Then, using the differenced matrices, the matrices
    #  are processed and prepared for figure creation.  Along the way the species' Latin names are
    #  prepped for inclusion.  
    if(n_domain == 6) {
      
    # Domains compared: Increasing vs. Stable threshold 
    I.vec <- c("IL", "IM", "IH")
    S.vec <- c("SL", "SM", "SH")
    
    IvS <- bind_rows(map2(I.vec, S.vec, domain.diff.fcn, results.array = bootstrap_results, domain_n = domain.n)) %>%
      arrange(Species, Domain)
    
    # Domains compared: Increasing threshold, Low/Med/High comparisons
    I_LMH.vec1 <- c("IH", "IM", "IH")
    I_LMH.vec2 <- c("IL", "IL", "IM")
    
    I_LMH <- bind_rows(map2(I_LMH.vec1, I_LMH.vec2, domain.diff.fcn, results.array = bootstrap_results, domain_n = domain.n)) %>%
      arrange(Species, Domain)
    
    # Domains compared: Stable threshold, Low/Med/High comparisons
    S_LMH.vec1 <- c("SH", "SM", "SH")
    S_LMH.vec2 <- c("SL", "SL", "SM")
    
    S_LMH <- bind_rows(map2(S_LMH.vec1, S_LMH.vec2, domain.diff.fcn, results.array = bootstrap_results, domain_n = domain.n)) %>%
      arrange(Species, Domain)
    
    spp.names.fig <- spp.names %>% select(SPCD, GENUS, SPECIES) %>% 
      mutate(Species = paste0("X", SPCD)) %>%
      select(-SPCD)
    
    
    IvS2 <- diff.fig.prep.fcn(IvS, diff.levels = c("IL - SL", "IM - SM", "IH - SH"))
    I_LMH2 <- diff.fig.prep.fcn(I_LMH, diff.levels = c("IH - IL", "IH - IM", "IM - IL"))
    S_LMH2 <- diff.fig.prep.fcn(S_LMH, diff.levels = c("SH - SL", "SH - SM", "SM - SL"))
    
    
    saveRDS(list(IvS = IvS, I_LMH = I_LMH, S_LMH = S_LMH, 
                 IvS2 = IvS2, I_LMH2 = I_LMH2, S_LMH2 = S_LMH2, 
                 spp.names.fig = spp.names.fig), 
            file = paste0(save.loc.fcn(k), "Processed_6Domain_Data.RDS"))
    
    
    }
    
  }   # end k 
  
toc()


### Summary information: generated at this point to capture changes in RMD output files.
if(RUN.SUMMARY == TRUE) {
  source(paste0(CODE.LOC, "Manuscript_information.R"))
}



# Plotting the multi-species panels

if(n_domain == 6) {
  psig.dat <- read_csv(paste0(RESULTS.OTHER, "Permutation_results.csv"), show_col_types = FALSE) %>%
    ## Changing domain designations from A/B to I/S ##
    mutate(across(everything(), ~str_replace_all(., "A", "I")),
  mutate(across(everything(), ~str_replace_all(., "B", "S"))))
  
  PLT.MCPERM <- FALSE  # Plot the MC permutation asterisks? TRUE = yes, FALSE = no
  
  for(k in 1:2){ # 1 = growth, 2 = mortality
      plt.dat <- readRDS(paste0(save.loc.fcn(k), "Processed_6Domain_Data.RDS"))
      
    psig.join.fcn <- function(k, position) {
      pos.adj <- 3*(k-1) + position
      psig.cols <- grep(pos.adj, colnames(psig.dat))
      psig.spp <- grep("Species", colnames(psig.dat))
      join.table <- psig.dat[, c(psig.spp, psig.cols)] 
      names(join.table) <- c("Species", "Domain", "sig.dist")
      join.table <- join.table %>% mutate(
        symb = case_when(
          is.na(sig.dist) == TRUE ~ "",
          sig.dist > 0.05 ~ "--",
          sig.dist > 0.01 & sig.dist <= 0.05 ~ "*",
          sig.dist > 0.001 & sig.dist <= 0.01 ~ "**",
          sig.dist > 0 & sig.dist <= 0.001 ~ "***",
          sig.dist == 0 ~ "****",
          .default = "XX"
        ),
        yadj = ifelse(symb == "--", 0.075, -0.11)
      )
      return(join.table)
    }
    
    IvS2 <- cm2.fcn(k, results.table = plt.dat$IvS2) %>% left_join(psig.join.fcn(k, position = 1), by = c("Species", "Domain"))
    I_LMH2 <- cm2.fcn(k, results.table = plt.dat$I_LMH2) %>% left_join(psig.join.fcn(k, position = 2), by = c("Species", "Domain"))
    S_LMH2 <- cm2.fcn(k, results.table = plt.dat$S_LMH2) %>% left_join(psig.join.fcn(k, position = 3), by = c("Species", "Domain"))
    
    
    xlab.use <- switch(k, "1" = "Difference in Domain Growth Rates (cm\u00B2/decade)", "2" = "Difference in Domain Decadal Mortality Rate")  #  "Annual Growth Rate (in2/yr)"
    filename.use <- switch(k, "1" = "Growth_", "2" = "Mort_")
    
    legend.side <- switch(k, "1" = c(TRUE, TRUE, FALSE),
           "2" = c(FALSE, FALSE, TRUE))
    
    IvS2 <- IvS2 %>% mutate(Domain = factor(Domain, levels = c("IL - SL", "IM - SM", "IH - SH")))
    
    p1 <- diff.panel.fcn(IvS2, remove.y = FALSE, fig.title = "Increasing vs. Stable", lab.right = legend.side[1], plt.mcperm = PLT.MCPERM)
    p2 <- diff.panel.fcn(I_LMH2, remove.y = TRUE, fig.title = "Increasing, High/Med/Low", lab.right = legend.side[2], plt.mcperm = PLT.MCPERM)
    p3 <- diff.panel.fcn(S_LMH2, remove.y = TRUE, fig.title = "Stable, High/Med/Low", lab.right = legend.side[3], plt.mcperm = PLT.MCPERM)
    
    grand.x.lab <- ggdraw() + draw_label(xlab.use, x = 0.6, y = 0.5, size = 13, fontfamily = "Times New Roman") + theme_bw() + 
      theme(rect = element_blank())
    
    
    diff.plt <- p1 + p2 + p3 + 
      plot_layout(ncol = 3, widths = c(1, 1, 1)) +
      plot_annotation(
        caption = xlab.use,
        theme = theme(plot.caption = element_text(size = 13, hjust = 0.7, family = font_to_use))
      )
    
    
  #  diff.plt <- plot_grid(p1, p2, p3, ncol = 3, rel_widths = c(0.9, 0.5, 0.5)) 
  #  
  #  diff.plt2 <- plot_grid(diff.plt, grand.x.lab, 
  #                         ncol = 1, 
  #                         rel_heights = c(1, 0.03)) 
    
    ggsave(paste0(save.loc.fcn(k), filename.use, "Panel_Plot.png"), plot = diff.plt, device = ragg::agg_png, 
           width = 10, height = 10, units = 'in', res = 300)
  }
}



# Analysis Pathway 1: no subgroups of size or site class
for(k in 1:2){ # 1 = growth, 2 = mortality
  plt.dat <- readRDS(paste0(save.loc.fcn(k), "Domain_Analysis_Output.RDS"))
  plt.dat2 <- plt.dat$domain.summaries
  
  
  mort.grow.dat <- get(paste0("arrays.", ANALYSIS.TYPE[k])) 
  
  domain.matrix <- mort.grow.dat$domain.matrix
  domain.n <- mort.grow.dat$domain.n 
  quant.lims <- mort.grow.dat$quant.lims
  quant.lims.delta <- mort.grow.dat$quant.lims.delt
  
  
  
  # Plotting paired plots of mortality/growth by quantile and a scatterplot of plot distribution by quantiles.
  SEL.SPP %>% purrr::map(\(s) pair.plts.fcn(sppnum.to.plot = s, use.dat = plt.dat2, domain.matrix = domain.matrix,
                                            quant.lims = quant.lims, domain.n = domain.n, k = k, 
                                            SHINYAPP.IN.USE = FALSE, SHINY_FONTSIZE = SHINY.FONTSIZE)) 
}




